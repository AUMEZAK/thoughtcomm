{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2: Collect Hidden States from Multi-Agent Debate\n",
    "\n",
    "Runs multi-agent debate on 500 training problems and collects\n",
    "concatenated hidden states H_t from all agents.\n",
    "\n",
    "**Checkpoints every 50 examples to Google Drive for session recovery.**\n",
    "\n",
    "Estimated time:\n",
    "- Qwen-3-0.6B: ~2-4 hours on T4\n",
    "- Phi-4-mini: ~4-8 hours on A100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Setup\n!git clone https://github.com/AUMEZAK/thoughtcomm.git 2>/dev/null || echo 'Already cloned'\n%cd thoughtcomm\n!pip install -e . -q"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive for checkpoints\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "SAVE_DIR = '/content/drive/MyDrive/thoughtcomm_checkpoints/'\n",
    "import os\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from configs.config import ThoughtCommConfig\n",
    "from models.model_utils import load_model_and_tokenizer\n",
    "from pipeline.debate import MultiAgentDebate\n",
    "from pipeline.hidden_state_collector import HiddenStateCollector\n",
    "from data.math_data import load_math_dataset\n",
    "from data.gsm8k_data import load_gsm8k_dataset\n",
    "from utils.memory import print_memory_stats\n",
    "\n",
    "print_memory_stats('Initial: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose model (uncomment one)\n",
    "config = ThoughtCommConfig.for_qwen_0_6b()\n",
    "# config = ThoughtCommConfig.for_phi4_mini()\n",
    "\n",
    "MODEL_TAG = config.model_name.split('/')[-1]\n",
    "print(f'Model: {config.model_name}')\n",
    "print(f'Hidden size: {config.hidden_size}')\n",
    "print(f'n_h (3 agents): {config.n_h}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model, tokenizer = load_model_and_tokenizer(\n",
    "    config.model_name, dtype=config.dtype\n",
    ")\n",
    "print_memory_stats('After model load: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "math_train, math_eval = load_math_dataset(\n",
    "    num_train=config.num_train, num_eval=config.num_eval, level=config.math_level\n",
    ")\n",
    "gsm8k_train, gsm8k_eval = load_gsm8k_dataset(\n",
    "    num_train=config.num_train, num_eval=config.num_eval\n",
    ")\n",
    "print(f'MATH train: {len(math_train)}, eval: {len(math_eval)}')\n",
    "print(f'GSM8K train: {len(gsm8k_train)}, eval: {len(gsm8k_eval)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test: run debate on 1 problem\n",
    "debate = MultiAgentDebate(model, tokenizer, config)\n",
    "test_q = math_train[0]['question']\n",
    "print(f'Test question: {test_q[:100]}...')\n",
    "\n",
    "responses, hidden = debate.run_debate(test_q, extract_hidden=True)\n",
    "print(f'\\nRound 0 responses (first 200 chars each):')\n",
    "for i, r in enumerate(responses[0]):\n",
    "    print(f'  Agent {i}: {r[:200]}...')\n",
    "\n",
    "print(f'\\nHidden state shapes:')\n",
    "for r in range(len(hidden)):\n",
    "    for a in range(len(hidden[r])):\n",
    "        print(f'  Round {r}, Agent {a}: {hidden[r][a].shape}')\n",
    "\n",
    "print_memory_stats('After test: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect hidden states for MATH training set\n",
    "collector = HiddenStateCollector(debate, config)\n",
    "\n",
    "math_save_dir = os.path.join(SAVE_DIR, f'{MODEL_TAG}_math')\n",
    "H_math, meta_math = collector.collect(\n",
    "    math_train, save_dir=math_save_dir, checkpoint_every=50\n",
    ")\n",
    "print(f'MATH hidden states: {H_math.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect hidden states for GSM8K training set\n",
    "gsm8k_save_dir = os.path.join(SAVE_DIR, f'{MODEL_TAG}_gsm8k')\n",
    "H_gsm8k, meta_gsm8k = collector.collect(\n",
    "    gsm8k_train, save_dir=gsm8k_save_dir, checkpoint_every=50\n",
    ")\n",
    "print(f'GSM8K hidden states: {H_gsm8k.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify hidden states\n",
    "for name, H in [('MATH', H_math), ('GSM8K', H_gsm8k)]:\n",
    "    print(f'{name}:')\n",
    "    print(f'  Shape: {H.shape}')\n",
    "    print(f'  Mean: {H.mean():.4f}, Std: {H.std():.4f}')\n",
    "    print(f'  NaN: {H.isnan().any()}, Inf: {H.isinf().any()}')\n",
    "    # Cosine similarity between first two samples\n",
    "    cos_sim = torch.nn.functional.cosine_similarity(H[0:1], H[1:2]).item()\n",
    "    print(f'  Cosine sim (sample 0 vs 1): {cos_sim:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}