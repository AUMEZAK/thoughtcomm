{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 1: Synthetic Experiment (Section 5.1)\n",
    "\n",
    "Validates the identifiability theory from the paper.\n",
    "- No LLM required\n",
    "- Generates synthetic data with known latent structure\n",
    "- Trains sparsity-regularized AE and baseline AE\n",
    "- Reproduces Fig 3 (R² matrix) and Fig 4 (MCC across dimensions)\n",
    "\n",
    "**Estimated time: ~15 minutes on Colab T4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Setup: Clone repo and install\n# To push results back to GitHub, store a Personal Access Token in Colab Secrets:\n#   1. Go to https://github.com/settings/tokens → Generate new token (classic) → repo scope\n#   2. In Colab left sidebar → Secrets (key icon) → Add: name=\"GITHUB_TOKEN\", value=<your token>\n#   3. Toggle \"Notebook access\" ON\n\nimport os\ntry:\n    from google.colab import userdata\n    GITHUB_TOKEN = userdata.get('GITHUB_TOKEN')\n    REPO_URL = f'https://{GITHUB_TOKEN}@github.com/AUMEZAK/thoughtcomm.git'\nexcept Exception:\n    GITHUB_TOKEN = None\n    REPO_URL = 'https://github.com/AUMEZAK/thoughtcomm.git'\n\n!git clone {REPO_URL} thoughtcomm 2>/dev/null || echo 'Already cloned'\n%cd thoughtcomm\n!pip install -e . -q\n\n# Configure git for pushing results\n!git config user.email \"colab@thoughtcomm.dev\"\n!git config user.name \"ThoughtComm Colab\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from configs.config import ThoughtCommConfig\n",
    "from data.synthetic import generate_synthetic_data, generate_multi_setup_data\n",
    "from models.autoencoder import SparsityRegularizedAE\n",
    "from training.train_autoencoder import train_autoencoder, train_autoencoder_baseline\n",
    "from training.jacobian_utils import compute_binary_pattern\n",
    "from evaluation.synthetic_eval import compute_r2_matrix, compute_mcc_fast\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Setup: R² Matrix (Fig 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data (dim=128, basic setup)\n",
    "DIM = 128\n",
    "X, Z, B_true, group_indices, mixing_fn = generate_synthetic_data(\n",
    "    dim=DIM, num_samples=10000, seed=42\n",
    ")\n",
    "print(f'X shape: {X.shape}, Z shape: {Z.shape}')\n",
    "print(f'Group indices: {group_indices}')\n",
    "print(f'B_true non-zero fraction: {B_true.float().mean():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config for synthetic experiment\n",
    "config = ThoughtCommConfig(\n",
    "    n_z=DIM,\n",
    "    ae_hidden=256,\n",
    "    ae_num_layers=3,\n",
    "    ae_epochs=200,\n",
    "    ae_batch_size=128,\n",
    "    ae_lr=1e-3,\n",
    "    jacobian_l1_weight=0.01,\n",
    "    jacobian_sample_rows=32,\n",
    "    device=device,\n",
    ")\n",
    "# Override n_h for synthetic (2 observed variables, not 3 agents)\n",
    "config.hidden_size = DIM // 2  # each 'agent' has DIM//2 dims\n",
    "config.num_agents = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train sparsity-regularized AE (ours)\n",
    "print('Training sparsity-regularized AE...')\n",
    "ae_ours, loss_ours = train_autoencoder(X, config, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline AE (no sparsity)\n",
    "print('Training baseline AE...')\n",
    "ae_base, loss_base = train_autoencoder_baseline(X, config, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover latent estimates\n",
    "with torch.no_grad():\n",
    "    Z_hat_ours = ae_ours.encode(X.float().to(device)).cpu()\n",
    "    Z_hat_base = ae_base.encode(X.float().to(device)).cpu()\n",
    "\n",
    "# Compute R² matrices\n",
    "r2_ours, names = compute_r2_matrix(Z_hat_ours, Z, group_indices)\n",
    "r2_base, _ = compute_r2_matrix(Z_hat_base, Z, group_indices)\n",
    "\n",
    "print('Ours R² matrix:')\n",
    "print(np.round(r2_ours, 3))\n",
    "print('\\nBaseline R² matrix:')\n",
    "print(np.round(r2_base, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Fig 3: R² matrices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "for ax, r2, title in [(axes[0], r2_ours, 'Ours'), (axes[1], r2_base, 'Baseline')]:\n",
    "    im = ax.imshow(r2, cmap='Blues', vmin=0, vmax=0.8)\n",
    "    ax.set_title(title, fontsize=14)\n",
    "    ax.set_xticks(range(3))\n",
    "    ax.set_yticks(range(3))\n",
    "    labels = ['$Z_A \\\\setminus Z_B$', '$Z_A \\\\cap Z_B$', '$Z_B \\\\setminus Z_A$']\n",
    "    ax.set_xticklabels(labels, fontsize=10)\n",
    "    ax.set_yticklabels(labels, fontsize=10)\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            ax.text(j, i, f'{r2[i,j]:.2f}', ha='center', va='center', fontsize=12)\n",
    "    plt.colorbar(im, ax=ax)\n",
    "\n",
    "plt.suptitle('Figure 3: R² of two models', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('fig3_r2_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MCC Across Dimensions (Fig 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sweep across dimensions\n",
    "dims = [128, 256, 384, 512, 640, 768, 896, 1024]\n",
    "mcc_results = []\n",
    "\n",
    "for dim in dims:\n",
    "    print(f'\\nDimension: {dim}')\n",
    "    X_d, Z_d, _, gi_d, _ = generate_synthetic_data(dim=dim, num_samples=10000)\n",
    "    \n",
    "    cfg = ThoughtCommConfig(\n",
    "        n_z=dim, ae_hidden=max(256, dim//2), ae_num_layers=3,\n",
    "        ae_epochs=200, ae_batch_size=128, ae_lr=1e-3,\n",
    "        jacobian_l1_weight=0.01, jacobian_sample_rows=32,\n",
    "        device=device,\n",
    "    )\n",
    "    cfg.hidden_size = dim // 2\n",
    "    cfg.num_agents = 2\n",
    "    \n",
    "    ae_d, _ = train_autoencoder(X_d, cfg, verbose=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        Z_hat_d = ae_d.encode(X_d.float().to(device)).cpu()\n",
    "    \n",
    "    mcc, _ = compute_mcc_fast(Z_hat_d, Z_d)\n",
    "    mcc_results.append(mcc)\n",
    "    print(f'  MCC: {mcc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Fig 4: MCC across dimensions\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(dims, mcc_results, 'b-o', linewidth=2, markersize=8)\n",
    "plt.axhline(y=0.75, color='r', linestyle='--', label='Identifiability threshold')\n",
    "plt.xlabel('Dimension', fontsize=12)\n",
    "plt.ylabel('MCC', fontsize=12)\n",
    "plt.title('Figure 4: MCC across setups', fontsize=14)\n",
    "plt.legend(fontsize=11)\n",
    "plt.xticks(dims)\n",
    "plt.ylim(0.7, 1.0)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('fig4_mcc.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize B matrix structure\n",
    "with torch.no_grad():\n",
    "    Z_sample = ae_ours.encode(X[:64].float().to(device))\n",
    "B_estimated = compute_binary_pattern(ae_ours.decoder, Z_sample, threshold=0.01, sub_batch=8, device=device)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes[0].imshow(B_true.numpy(), cmap='Blues', aspect='auto')\n",
    "axes[0].set_title('Ground Truth B', fontsize=12)\n",
    "axes[0].set_xlabel('Latent dims')\n",
    "axes[0].set_ylabel('Observed dims')\n",
    "\n",
    "axes[1].imshow(B_estimated.numpy(), cmap='Blues', aspect='auto')\n",
    "axes[1].set_title('Estimated B (ours)', fontsize=12)\n",
    "axes[1].set_xlabel('Latent dims')\n",
    "axes[1].set_ylabel('Observed dims')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('b_matrix_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'B_true sparsity: {1 - B_true.float().mean():.3f}')\n",
    "print(f'B_est sparsity: {1 - B_estimated.float().mean():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Expected results:\n",
    "- **Fig 3 (left/Ours)**: High R² on diagonal (~0.6-0.8), low off-diagonal (~0-0.1)\n",
    "- **Fig 3 (right/Baseline)**: Poorly disentangled, high off-diagonal R²\n",
    "- **Fig 4**: MCC > 0.75 (red threshold) across all dimensions\n",
    "- **B matrix**: Estimated B shows block-sparse structure similar to ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Push Results to GitHub",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Save results and push to GitHub\nimport json\n\n# Save numerical results as JSON (not .pt, so it's readable on GitHub)\nresults_01 = {\n    'r2_ours': r2_ours.tolist(),\n    'r2_baseline': r2_base.tolist(),\n    'mcc_dims': dims,\n    'mcc_values': mcc_results,\n    'b_true_sparsity': float(1 - B_true.float().mean()),\n    'b_est_sparsity': float(1 - B_estimated.float().mean()),\n}\n\nos.makedirs('results', exist_ok=True)\nwith open('results/01_synthetic_results.json', 'w') as f:\n    json.dump(results_01, f, indent=2)\n\n# Copy figures to results/\n!cp fig3_r2_matrix.png results/\n!cp fig4_mcc.png results/\n!cp b_matrix_comparison.png results/\n\n# Git add, commit, push\n!git add results/\n!git commit -m \"Add Notebook 01 results: synthetic experiment (Fig 3, 4)\"\n!git push\n\nprint('Results pushed to GitHub!')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}